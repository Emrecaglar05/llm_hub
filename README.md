# ğŸš€ My LLM & AI Learning Journey

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-00D9FF?style=for-the-badge&logo=python&logoColor=white)
![LLMs](https://img.shields.io/badge/LLMs-Transformers-00D9FF?style=for-the-badge&logo=huggingface&logoColor=white)
![Status](https://img.shields.io/badge/Status-In%20Progress-00D9FF?style=for-the-badge)

*Personal repository documenting my journey in mastering Large Language Models, NLP, and AI technologies*

</div>

---

## ğŸ“š Learning Path Overview

This repository contains my hands-on projects and implementations as I progress through advanced LLM and AI concepts. Each module represents a milestone in my data science journey.

### ğŸ¯ Learning Objectives
- Master LLM fundamentals and architectures
- Develop expertise in prompt engineering techniques
- Optimize model pipelines for production
- Build RAG (Retrieval-Augmented Generation) systems
- Create advanced LangChain applications

---

## ğŸ“‚ Repository Structure

```
my-llm-journey/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ .gitignore               # Git ignore rules
â”‚
â”œâ”€â”€ module_1_llm_basics/     # Foundation: LLM Fundamentals
â”‚   â”œâ”€â”€ turkish_simple.py    # Turkish language model experiments
â”‚   â”œâ”€â”€ microsoft_phi.py     # Microsoft Phi model implementation
â”‚   â”œâ”€â”€ qwen_model.py        # Qwen model exploration
â”‚   â””â”€â”€ llm_env/            # Virtual environment
â”‚
â”œâ”€â”€ module_2_prompt_engineering/  # Advanced Prompting Techniques
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ 01_zero_shot.py          # Zero-shot learning
â”‚   â”œâ”€â”€ 02_few_shot.py           # Few-shot learning
â”‚   â”œâ”€â”€ 03_chain_of_thought.py   # CoT prompting
â”‚   â”œâ”€â”€ 04_role_based.py         # Role-based prompts
â”‚   â”œâ”€â”€ 05_chat_api.py           # Chat completion API
â”‚   â”œâ”€â”€ 06_function_calling.py   # Function calling
â”‚   â”œâ”€â”€ 07_functional_chatbot.py # Chatbot with functions
â”‚   â”œâ”€â”€ 08_simple_chatbot.py     # Basic chatbot
â”‚   â”œâ”€â”€ 09_web_chatbot.py        # Web-based chatbot
â”‚   â””â”€â”€ prompt_env/              # Virtual environment
â”‚
â”œâ”€â”€ module_3_pipeline_optimization/  # Performance & Optimization
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ SETUP.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ setup.sh                     # Setup script (macOS/Linux)
â”‚   â”œâ”€â”€ setup.bat                    # Setup script (Windows)
â”‚   â”œâ”€â”€ 01_autotokenizer_automodel.py
â”‚   â”œâ”€â”€ 02_model_comparison.py       # GPT vs BERT vs T5
â”‚   â”œâ”€â”€ 03_cpu_gpu_optimization.py   # Hardware optimization
â”‚   â”œâ”€â”€ 04_performance_metrics.py    # Benchmarking
â”‚   â””â”€â”€ pipeline_env/                # Virtual environment
â”‚
â”œâ”€â”€ module_4_vector_search_rag/      # RAG Systems
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ simple_rag_demo.py
â”‚   â”œâ”€â”€ chroma_vector_search.py
â”‚   â”œâ”€â”€ pinecone_integration.py
â”‚   â”œâ”€â”€ project_notes.md
â”‚   â””â”€â”€ diagrams/
â”‚
â””â”€â”€ module_5_advanced_langchain/     # Advanced LangChain
    â”œâ”€â”€ README.md
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ setup_venv.py
    â”œâ”€â”€ test_installation.py
    â”œâ”€â”€ 1_chains_basic.py
    â”œâ”€â”€ 2_memory_examples.py
    â”œâ”€â”€ 3_tools_and_agents.py
    â”œâ”€â”€ 4_real_world_scenarios.py
    â”œâ”€â”€ 5_streaming_examples.py
    â””â”€â”€ project_notes.md
```

---

## ğŸ› ï¸ Quick Start

### Prerequisites
```bash
Python 3.8+
pip or conda
8GB+ RAM (16GB recommended)
GPU optional (speeds up training/inference)
```

### Installation

**Option 1: Clone Repository**
```bash
git clone https://github.com/Emrecaglar05/my-llm-journey.git
cd my-llm-journey
```

**Option 2: Start with Specific Module**
```bash
cd module_3_pipeline_optimization

# macOS/Linux
chmod +x setup.sh
./setup.sh

# Windows
setup.bat
```

### API Keys Setup
Create a `.env` file in the project root:
```bash
# OpenAI (for Module 2+)
OPENAI_API_KEY=your_openai_key_here

# Hugging Face (for Module 3+)
HUGGINGFACE_TOKEN=your_hf_token_here

# Pinecone (for Module 4)
PINECONE_API_KEY=your_pinecone_key_here
PINECONE_ENV=your_pinecone_environment
```

---

## ğŸ“– Module Details

### ğŸ¯ Module 1: LLM Fundamentals
**Status:** âœ… Completed  
**Focus:** Understanding transformer architectures, tokenization, and basic model usage

**Key Learnings:**
- Transformer architecture fundamentals
- Tokenization methods (BPE, WordPiece)
- Model loading and inference
- Turkish NLP models

### ğŸ¯ Module 2: Prompt Engineering
**Status:** âœ… Completed  
**Focus:** Mastering different prompting techniques and chat APIs

**Key Learnings:**
- Zero-shot and few-shot learning
- Chain-of-thought prompting
- Function calling with OpenAI API
- Building conversational AI systems

### ğŸ¯ Module 3: Pipeline Optimization
**Status:** ğŸ”„ In Progress  
**Focus:** Optimizing model performance and deployment

**Key Learnings:**
- CPU vs GPU optimization techniques
- Model quantization and pruning
- Batch processing strategies
- Performance benchmarking

**System Requirements:**
- **Minimum:** 8 GB RAM, Python 3.8+
- **Recommended:** 16 GB RAM, GPU (CUDA/MPS)
- **Storage:** 10 GB free space for model cache

**Supported Platforms:**
- macOS (Native MPS support for Apple Silicon)
- Linux (CUDA GPU support)
- Windows (CUDA GPU and CPU support)

### ğŸ¯ Module 4: Vector Search & RAG
**Status:** ğŸ“… Planned  
**Focus:** Building retrieval-augmented generation systems

**Planned Topics:**
- Vector embeddings and similarity search
- ChromaDB and Pinecone integration
- Document chunking strategies
- RAG system architecture

### ğŸ¯ Module 5: Advanced LangChain
**Status:** ğŸ“… Planned  
**Focus:** Complex chains, agents, and production systems

**Planned Topics:**
- Advanced chain architectures
- Memory management
- Custom tools and agents
- Streaming responses
- Production deployment

---

## ğŸ’¡ Personal Notes & Insights

### ğŸŒŸ Key Takeaways
- **LLM Selection:** Choose models based on use case, not just size
- **Prompt Engineering:** Precision in prompts = better outputs
- **Optimization:** GPU isn't always necessary; optimize for your hardware
- **RAG Benefits:** Reduces hallucinations, enables real-time knowledge

### ğŸ“ Learning Resources
- [Hugging Face Course](https://huggingface.co/learn)
- [LangChain Documentation](https://python.langchain.com/)
- [OpenAI Cookbook](https://github.com/openai/openai-cookbook)
- [Pinecone Learning Center](https://www.pinecone.io/learn/)

---

## ğŸ”§ Technical Stack

### Core Technologies
![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat-square&logo=tensorflow&logoColor=white)
![Transformers](https://img.shields.io/badge/ğŸ¤—%20Transformers-FFD21E?style=flat-square)

### Frameworks & Libraries
- **LLM Frameworks:** LangChain, LlamaIndex
- **Vector DBs:** ChromaDB, Pinecone, FAISS
- **APIs:** OpenAI, Hugging Face, Cohere
- **Tools:** Jupyter, Google Colab, VS Code

---

## ğŸ“Š Progress Tracker

| Module | Status | Completion | Projects | Notes |
|--------|--------|-----------|----------|-------|
| Module 1 | âœ… | 100% | 3 | Turkish NLP focus |
| Module 2 | âœ… | 100% | 9 | OpenAI API mastery |
| Module 3 | ğŸ”„ | 60% | 4 | GPU optimization ongoing |
| Module 4 | ğŸ“… | 0% | 0 | Starting soon |
| Module 5 | ğŸ“… | 0% | 0 | Planned for next phase |

---

## ğŸ¯ Goals & Milestones

### Short-term (Next 2 months)
- [ ] Complete Module 3 optimization projects
- [ ] Build first production-ready RAG system
- [ ] Deploy chatbot with vector search
- [ ] Contribute to open-source LLM project

### Long-term (6 months)
- [ ] Master LangChain advanced patterns
- [ ] Build portfolio of 5 LLM applications
- [ ] Write technical blog posts on learnings
- [ ] Participate in AI/ML hackathons

---

## ğŸ“ Project Documentation

Each module contains:
- **README.md:** Module overview and objectives
- **requirements.txt:** Python dependencies
- **project_notes.md:** Personal insights and challenges
- **Code files:** Annotated implementations

---

## ğŸ¤ Connect & Collaborate

I'm always open to discussions about LLMs, AI, and data science!

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/emre-%C3%A7a%C4%9Flar-9bb493294/)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=for-the-badge&logo=github)](https://github.com/Emrecaglar05)
[![Kaggle](https://img.shields.io/badge/Kaggle-Follow-20BEFF?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/emrecaglar05)
[![Email](https://img.shields.io/badge/Email-Contact-EA4335?style=for-the-badge&logo=gmail&logoColor=white)](mailto:emrecaglar05@gmail.com)

---

## ğŸ“œ License

This project is licensed under the MIT License - feel free to use and adapt for your own learning journey.

---

<div align="center">

**ğŸš€ "Learning by doing - one model at a time"**

*Last Updated: November 2024*

![Visitor Count](https://komarev.com/ghpvc/?username=Emrecaglar05&color=00D9FF&style=flat-square)

</div>
